import os
import json
import glob
import pandas as pd
import streamlit as st
from PIL import Image, ImageOps

import torch
import torch.nn.functional as F
from torchvision import transforms, models


# ----------------------------
# Page + CSS (bigger uploader + buttons)
# ----------------------------
st.set_page_config(page_title="Pet Emotion Classifier", layout="centered")
st.title("ğŸ¾ å¯µç‰©æƒ…ç·’/è¡¨æƒ…è¾¨è­˜ Demoï¼ˆå–®æ¨¡å‹ç‰ˆï¼‰")
st.caption("ä¸Šå‚³åœ–ç‰‡ â†’ï¼ˆå¯é¸ï¼‰è‡ªå‹•ä¸»é«”è£åˆ‡ â†’ è¼¸å‡ºå››ç¨®æƒ…ç·’æ©Ÿç‡åˆ†å¸ƒ")

st.markdown(
    """
<style>
/* æ”¾å¤§ file_uploader */
div[data-testid="stFileUploader"] section {
    padding: 18px 14px;
}
div[data-testid="stFileUploader"] button {
    font-size: 18px !important;
    padding: 10px 18px !important;
}
div[data-testid="stFileUploader"] small {
    font-size: 14px !important;
}

/* æ”¾å¤§ä¸€èˆ¬æŒ‰éˆ• */
div.stButton > button {
    font-size: 16px !important;
    padding: 10px 14px !important;
}
</style>
""",
    unsafe_allow_html=True,
)


# ----------------------------
# Model loading (single model: pet_emotion_*.pt/json)
# ----------------------------
def load_latest_model(models_dir: str = "models", prefix: str = "pet_emotion"):
    pts = sorted(glob.glob(os.path.join(models_dir, f"{prefix}_*.pt")))
    metas = sorted(glob.glob(os.path.join(models_dir, f"{prefix}_*.json")))
    if not pts or not metas:
        return None, None, None, None, None

    model_path = pts[-1]
    meta_path = metas[-1]

    with open(meta_path, "r", encoding="utf-8") as f:
        meta = json.load(f)

    classes = meta["classes"]
    img_size = int(meta.get("img_size", 224))

    model = models.efficientnet_b0(weights=None)
    in_features = model.classifier[1].in_features
    model.classifier[1] = torch.nn.Linear(in_features, len(classes))

    state = torch.load(model_path, map_location="cpu")
    model.load_state_dict(state)
    model.eval()

    return model, classes, img_size, model_path, meta_path


def preprocess(img: Image.Image, img_size: int):
    tf = transforms.Compose(
        [
            transforms.Resize((img_size, img_size)),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225],
            ),
        ]
    )
    return tf(img).unsqueeze(0)


@torch.no_grad()
def predict_all(model, classes, img: Image.Image, img_size: int):
    x = preprocess(img, img_size)
    logits = model(x)
    probs = F.softmax(logits, dim=1).cpu().numpy().reshape(-1)
    return {classes[i]: float(probs[i]) for i in range(len(classes))}


def normalize_label(s: str) -> str:
    """
    æŠŠæ¨™ç±¤çµ±ä¸€æˆå°å¯«ï¼Œä¸¦ç°¡å–®è™•ç† other/others é€™ç¨®å¸¸è¦‹å·®ç•°
    """
    s2 = (s or "").strip().lower()
    if s2 == "others":
        return "other"
    return s2


# ----------------------------
# Load model
# ----------------------------
models_dir = "models"
model, classes, img_size, model_path, meta_path = load_latest_model(models_dir, prefix="pet_emotion")

if model is None:
    st.warning(
        "æ‰¾ä¸åˆ° pet_emotion_* æ¨¡å‹ã€‚\n\n"
        "è«‹å…ˆè¨“ç·´å–®æ¨¡å‹ï¼š\n"
        "- python train.py --data_dir data --tag pet_emotion\n"
    )
    st.stop()

# å›ºå®šé¡¯ç¤º 4 é¡ï¼ˆä¾ä½ çš„éœ€æ±‚ï¼‰
# æœƒç”¨ normalize_label å°é½Š classes åç¨±
DISPLAY_CLASSES = ["happy", "sad", "angry", "other"]

# é¡¯ç¤ºç”¨ï¼šæª¢æŸ¥æ¨¡å‹å¯¦éš› classes
with st.expander("ğŸ” æ¨¡å‹è³‡è¨Šï¼ˆclasses / æª”æ¡ˆï¼‰", expanded=False):
    st.write("classes:", classes)
    st.write("model:", model_path)
    st.write("meta:", meta_path)
    missing = [c for c in DISPLAY_CLASSES if c not in [normalize_label(x) for x in classes]]
    if missing:
        st.warning(f"æ³¨æ„ï¼šæ¨¡å‹ classes å…§æ‰¾ä¸åˆ°ä»¥ä¸‹é¡åˆ¥ï¼š{missing}ï¼ˆå¯èƒ½å‘½åä¸åŒæˆ–è¨“ç·´è³‡æ–™å¤¾åç¨±ä¸ä¸€è‡´ï¼‰")


# ----------------------------
# Inputs: upload + sample
# ----------------------------
st.subheader("è¼¸å…¥åœ–ç‰‡")

colA, colB = st.columns([2, 1])

with colA:
    uploaded = st.file_uploader("ä¸Šå‚³å¯µç‰©ç…§ç‰‡ï¼ˆjpg/pngï¼‰", type=["jpg", "jpeg", "png", "webp"])

with colB:
    sample_files = sorted(
        glob.glob("samples/*.jpg")
        + glob.glob("samples/*.jpeg")
        + glob.glob("samples/*.png")
        + glob.glob("samples/*.webp")
    )
    sample_options = ["ï¼ˆä¸ä½¿ç”¨ï¼‰"] + [os.path.basename(p) for p in sample_files]
    sample_name = st.selectbox("æˆ–é¸æ“‡ç¯„ä¾‹åœ–ç‰‡", sample_options)
    use_sample = st.button("ç”¨ç¯„ä¾‹åœ–ç‰‡æ¸¬è©¦", use_container_width=True)

    # ROI è£åˆ‡é¸é …ï¼šä¸é¡¯ç¤º ROIã€ä¸é¡¯ç¤º cat/dogï¼Œåªç•¶æˆå…§éƒ¨å‰è™•ç†
    use_detect = st.checkbox("å•Ÿç”¨è‡ªå‹•ä¸»é«”è£åˆ‡ï¼ˆå»ºè­°ï¼‰", value=True)
    conf_thres = st.slider("è£åˆ‡åµæ¸¬ä¿¡å¿ƒé–¾å€¼", min_value=0.05, max_value=0.90, value=0.25, step=0.05)

img = None
img_source = None

if use_sample and sample_name != "ï¼ˆä¸ä½¿ç”¨ï¼‰":
    sample_path = [p for p in sample_files if os.path.basename(p) == sample_name][0]
    img = Image.open(sample_path).convert("RGB")
    img_source = f"ç¯„ä¾‹åœ–ç‰‡ï¼š{sample_name}"
elif uploaded is not None:
    img = Image.open(uploaded).convert("RGB")
    img_source = "ä¸Šå‚³åœ–ç‰‡"

if img is None:
    st.info("è«‹ä¸Šå‚³åœ–ç‰‡ï¼Œæˆ–é¸æ“‡ç¯„ä¾‹åœ–ç‰‡ä¸¦æŒ‰ä¸‹ã€Œç”¨ç¯„ä¾‹åœ–ç‰‡æ¸¬è©¦ã€ã€‚")
    st.stop()

# Fix EXIF rotation
img = ImageOps.exif_transpose(img)

st.image(img, caption=f"{img_source}", use_container_width=True)


# ----------------------------
# Optional detect + ROI crop (lazy import, cloud-safe)
# ----------------------------
roi_img = img

detector = None
if use_detect:
    try:
        # Lazy import: é¿å…éƒ¨ç½²ç’°å¢ƒå›  cv2/ultralytics ç›´æ¥æ›æ‰
        from detector import PetDetector  # noqa: F401

        detector = PetDetector("yolov8n.pt")
    except Exception:
        # ä¸é¡¯ç¤ºéŒ¯èª¤ç´°ç¯€ï¼ˆé›²ç«¯å¸¸æœƒ redactedï¼‰ï¼Œåªåšé™ç´šæç¤º
        st.warning("è‡ªå‹•ä¸»é«”è£åˆ‡åœ¨ç›®å‰éƒ¨ç½²ç’°å¢ƒç„¡æ³•å•Ÿç”¨ï¼Œå·²æ”¹ç”¨åŸåœ–é€²è¡Œæ¨è«–ã€‚")
        detector = None
        use_detect = False

if use_detect and detector is not None:
    try:
        det = detector.detect_and_crop(img, conf_thres=conf_thres, pad_ratio=0.10)
        roi_img = det.crop
    except Exception:
        # è£åˆ‡å¤±æ•—ä¹Ÿè¦èƒ½å›é€€ï¼Œä¸å½±éŸ¿ä¸»æµç¨‹
        roi_img = img


# ----------------------------
# Predict: fixed 4 classes + full table + bar chart
# ----------------------------
raw_probs = predict_all(model, classes, roi_img, img_size)

# å°‡æ¨¡å‹è¼¸å‡ºæ˜ å°„åˆ°å›ºå®šå››é¡ï¼ˆä»¥ normalize_label å°é½Šï¼‰
norm_map = {normalize_label(k): v for k, v in raw_probs.items()}

# è‹¥æ¨¡å‹æœ¬èº«é¡åˆ¥å‘½åä¸åŒï¼ˆä¾‹å¦‚ Other/othersï¼‰ï¼Œé€™è£¡æœƒç›¡é‡å°é½Š
fixed_items = []
for c in DISPLAY_CLASSES:
    fixed_items.append((c, float(norm_map.get(c, 0.0))))

# ä¾æ©Ÿç‡é«˜åˆ°ä½æ’åºé¡¯ç¤ºï¼ˆä½†æ°¸é é¡¯ç¤ºå››é¡ï¼‰
fixed_items_sorted = sorted(fixed_items, key=lambda x: x[1], reverse=True)

st.subheader("æ¨è«–çµæœï¼ˆå››ç¨®æƒ…ç·’æ©Ÿç‡ï¼‰")
for label, p in fixed_items_sorted:
    st.write(f"**{label}**ï¼š{p * 100:.2f}%")

st.divider()
st.caption("å®Œæ•´æ©Ÿç‡è¡¨èˆ‡åœ–è¡¨ï¼ˆå›ºå®šå››é¡ï¼‰")

df = pd.DataFrame(fixed_items_sorted, columns=["label", "prob"])
df["prob_%"] = df["prob"] * 100.0

st.dataframe(df[["label", "prob_%"]], use_container_width=True, hide_index=True)
st.bar_chart(df.set_index("label")[["prob_%"]])
